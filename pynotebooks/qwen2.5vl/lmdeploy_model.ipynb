{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### align `lmdeploy` forward precision with `transformers` forward precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"transformers initialize\"\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, Qwen2_5_VLConfig\n",
    "\n",
    "model_path = \"/models/Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "config = Qwen2_5_VLConfig.from_pretrained(model_path)\n",
    "transformer_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(model_path,device_map=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"lmdpeloy initialize\"\n",
    "import torch\n",
    "from lmdeploy import PytorchEngineConfig\n",
    "from lmdeploy.pytorch.config import BackendConfig, CacheConfig, ModelConfig\n",
    "from lmdeploy.pytorch.configurations import AutoModelConfigBuilder\n",
    "from lmdeploy.pytorch.multimodal import MultiModalTensor\n",
    "from lmdeploy.pytorch.model_inputs import StepContextManager, ModelInputs, VisionModelInputs\n",
    "from lmdeploy.pytorch.models.qwen2_5_vl import Qwen2_5_VLForConditionalGeneration as lmdeploy_Qwen2_5_VL\n",
    "device=\"cuda:0\"\n",
    "\n",
    "engine_config=PytorchEngineConfig(cache_max_entry_count=0.4)\n",
    "\n",
    "backend_config = BackendConfig(eager_mode=False,device_type='cuda')\n",
    "\n",
    "model_config:ModelConfig = AutoModelConfigBuilder.build(\n",
    "    hf_config=config, model_path=model_path, tp=1\n",
    ")\n",
    "model_config.k_head_dim = model_config.v_head_dim = 128\n",
    "# rich.print(\"[ModelConfig]\\n\",model_config)\n",
    "\n",
    "cache_config = CacheConfig(\n",
    "    max_batches=engine_config.max_batch_size,\n",
    "    block_size=engine_config.block_size,\n",
    "    num_cpu_blocks=engine_config.num_cpu_blocks,\n",
    "    num_gpu_blocks=engine_config.num_gpu_blocks,\n",
    "    cache_max_entry_count=engine_config.cache_max_entry_count,\n",
    "    max_prefill_token_num=engine_config.max_prefill_token_num,\n",
    "    enable_prefix_caching=engine_config.enable_prefix_caching,\n",
    "    quant_policy=engine_config.quant_policy,\n",
    "    device_type=engine_config.device_type,\n",
    ")\n",
    "ctx_mgr = StepContextManager()\n",
    "inputs = ModelInputs(\n",
    "    input_ids=...,\n",
    "    seq_length=torch.Tensor([0]).to(device=device,dtype=torch.int64),\n",
    "    history_lengths=torch.Tensor([0]).to(device,dtype=torch.int64),\n",
    "    block_offsets=torch.arange(22,device=device,dtype=torch.int64),\n",
    "    is_decoding=False,\n",
    "    num_ignored_history=torch.Tensor([0]).to(device=device,dtype=torch.int64),\n",
    "    local_adapter_ids=None,\n",
    "    vision_inputs=VisionModelInputs(\n",
    "        history_lengths=torch.Tensor([0]).to(device=device,dtype=torch.int64),\n",
    "        history_image_nums=None,\n",
    "        history_image_token_lengths=None,\n",
    "        input_embeddings=None,\n",
    "        input_embedding_ranges=None,\n",
    "        input_embedding_indexing=None,\n",
    "        input_multimodals={\n",
    "            \"image\":[\n",
    "                MultiModalTensor(\n",
    "                    data=torch.Tensor([...]),\n",
    "                    encoder_len=None,\n",
    "                    end=1384,\n",
    "                    meta={'grid_thw':torch.Tensor}\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    ),\n",
    "    cross_length=None,\n",
    "    history_cross_length=None,\n",
    "    model_metas=[None]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
